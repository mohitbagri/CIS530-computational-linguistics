{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, csv, subprocess, re, random\n",
    "# os.chdir(\"lyz\")\n",
    "import numpy as np\n",
    "import time\n",
    "import multiprocessing, platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_shakespeare():\n",
    "    '''Reads in the Shakespeare dataset processesit into a list of tuples.\n",
    "     Also reads in the vocab and play name lists from files.\n",
    "\n",
    "    Each tuple consists of\n",
    "    tuple[0]: The name of the play\n",
    "    tuple[1] A line from the play as a list of tokenized words.\n",
    "\n",
    "    Returns:\n",
    "        tuples: A list of tuples in the above format.\n",
    "        document_names: A list of the plays present in the corpus.\n",
    "        vocab: A list of all tokens in the vocabulary.\n",
    "    '''\n",
    "\n",
    "    tuples = []\n",
    "    with open('will_play_text.csv') as f:\n",
    "        csv_reader = csv.reader(f, delimiter=';')\n",
    "        for row in csv_reader:\n",
    "            play_name = row[1]\n",
    "            line = row[5]\n",
    "            line_tokens = re.sub(r'[^a-zA-Z0-9\\s]', ' ', line).split()\n",
    "            line_tokens = [token.lower() for token in line_tokens]\n",
    "            tuples.append((play_name, line_tokens))\n",
    "        f.close()\n",
    "    with open('vocab.txt') as f: \n",
    "        vocab = [line.strip() for line in f.readlines()]\n",
    "        f.close()\n",
    "    with open('play_names.txt') as f: \n",
    "        document_names =  [line.strip() for line in f]\n",
    "        f.close()\n",
    "    return tuples, document_names, vocab\n",
    "\n",
    "def create_term_document_matrix(line_tuples, document_names, vocab):\n",
    "    '''Returns a numpy array containing the term document matrix for the input lines.\n",
    "    Inputs:\n",
    "    line_tuples: A list of tuples, containing the name of the document and \n",
    "    a tokenized line from that document.\n",
    "    document_names: A list of the document names\n",
    "    vocab: A list of the tokens in the vocabulary\n",
    "    # NOTE: THIS DOCSTRING WAS UPDATED ON JAN 24, 12:39 PM.\n",
    "\n",
    "    Let m = len(vocab) and n = len(document_names).\n",
    "\n",
    "    Returns:\n",
    "        td_matrix: A mxn numpy array where the number of rows is the number of words\n",
    "          and each column corresponds to a document. A_ij contains the\n",
    "          frequency with which word i occurs in document j.\n",
    "    '''\n",
    "#     from collections import Counter, defaultdict\n",
    "#     Dict_doc_words_Counter = defaultdict(Counter)\n",
    "#     for d, wList in line_tuples: Dict_doc_words_Counter[d] += Counter(wList)\n",
    "    vocab_to_id = dict(zip(vocab, range(0, len(vocab))))\n",
    "    docname_to_id = dict(zip(document_names, range(0, len(document_names))))\n",
    "    n_docs = len(document_names)\n",
    "    n_words = len(vocab)\n",
    "    ret = np.zeros((n_words, n_docs), dtype = np.int32)\n",
    "    for d, wList in line_tuples: \n",
    "        doc_idx = docname_to_id[d]\n",
    "        for w in wList: ret[vocab_to_id[w]][doc_idx] += 1\n",
    "# --------------\n",
    "# not parallel\n",
    "#     ret = [[Dict_doc_words_Counter[doc][w] for w in vocab] for doc in document_names] # fastest on Macbook\n",
    "# not parallel\n",
    "# --------------\n",
    "# parallel\n",
    "#     num_cores = multiprocessing.cpu_count()\n",
    "#     print(\"num of cores:\", num_cores)\n",
    "#     pool = multiprocessing.Pool(processes=num_cores)\n",
    "#     ret = pool.map(process_impv, ((Dict_doc_words_Counter[doc],vocab) for doc in document_names) ) \n",
    "# parallel\n",
    "# --------------\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_cosine_similarity(v1, v2): \n",
    "#     '''Computes the cosine similarity of the two input vectors.\n",
    "#     Inputs:()\n",
    "#     v1: A nx1 numpy array \n",
    "#     v2: A nx1 numpy array \n",
    "\n",
    "#     Returns:\n",
    "#     A scalar similarity value. # a numpy array if multiple dimension\n",
    "#     '''\n",
    "#     ret = sum(np.multiply(v1, v2))\n",
    "#     if 0 == ret: return ret\n",
    "#     ret = ret/ (np.linalg.norm(v1)*np.linalg.norm(v2))\n",
    "# #     if 1 == len(vector1.shape) and 1 == len(vector1.shape): return ret[0] # np.double\n",
    "#     return ret\n",
    "\n",
    "def compute_cosine_similarity(vector1, vector2):\n",
    "  '''Computes the cosine similarity of the two input vectors.\n",
    "\n",
    "  Inputs:\n",
    "    vector1: A nx1 numpy array\n",
    "    vector2: A nx1 numpy array\n",
    "\n",
    "  Returns:\n",
    "    A scalar similarity value.\n",
    "  '''\n",
    "  n1=int(vector1.T.dot(vector1))\n",
    "  n2=int(vector2.T.dot(vector2))\n",
    "  if( n1==0 or n2==0 ) :  sim = 0\n",
    "  else:\n",
    "      sim =  float(vector1.T.dot(vector2)) / (  np.sqrt(n1)  *  np.sqrt(n2) )\n",
    "  return sim\n",
    "\n",
    "def compute_jaccard_similarity(vector1, vector2):\n",
    "    '''Computes the cosine similarity of the two input vectors.\n",
    "\n",
    "  Inputs:\n",
    "    vector1: A nx1 numpy array\n",
    "    vector2: A nx1 numpy array\n",
    "\n",
    "  Returns:\n",
    "    A scalar similarity value.\n",
    "  '''  \n",
    "    # http://scikit-learn.org/stable/modules/generated/sklearn.metrics.jaccard_similarity_score.html\n",
    "    ret = np.sum(np.minimum(vector1,vector2))/(np.sum(np.maximum(vector1, vector2)))\n",
    "    return ret\n",
    "\n",
    "def compute_dice_similarity(vector1, vector2):\n",
    "    '''Computes the cosine similarity of the two input vectors.\n",
    "\n",
    "  Inputs:\n",
    "    vector1: A nx1 numpy array\n",
    "    vector2: A nx1 numpy array\n",
    "\n",
    "  Returns:\n",
    "    A scalar similarity value.\n",
    "    '''\n",
    "    ret = np.sum(np.minimum(vector1,vector2))/(np.sum(vector1) + np.sum(vector2))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''----------------------------------------\n",
    "The fourth column of will_play_text.csv contains the name of the character who spokeeach line. Using the methods described above, which characters are most similar? Least similar?\n",
    "----------------------------------------\n",
    "'''\n",
    "def read_character_in_shakspeare():\n",
    "    '''Each tuple consists of\n",
    "    tuple[0]: The name of the play\n",
    "    tuple[1] A line from the play as a list of tokenized words.\n",
    "    Returns:\n",
    "        tuples: A list of tuples in the above format.\n",
    "        ch_names: A list of the plays present in the corpus.\n",
    "        vocab: A list of all tokens in the vocabulary.\n",
    "    '''\n",
    "\n",
    "    tuples = []\n",
    "    with open('will_play_text.csv') as f:\n",
    "        csv_reader = csv.reader(f, delimiter=';')\n",
    "        ch_names = set()\n",
    "        for row in csv_reader:\n",
    "            ch_name = row[4].strip().lower()\n",
    "            ch_names.add(ch_name)\n",
    "            line = row[5]\n",
    "            line_tokens = re.sub(r'[^a-zA-Z0-9\\s]', ' ', line).split()\n",
    "            line_tokens = [token.lower() for token in line_tokens]\n",
    "            tuples.append((ch_name, line_tokens))\n",
    "        f.close()\n",
    "#     with open('vocab.txt') as f: vocab = [line.strip() for line in f.readlines()]\n",
    "    ch_names = list(ch_names)\n",
    "    return tuples, ch_names#, vocab\n",
    "\n",
    "# def process_impv_rk_chs(args):\n",
    "#     sim_fn,v1,v2 = args\n",
    "#     return sim_fn(v1,v2)\n",
    "def rank_ch_return_max_min_maxIdx_minIdx(target_ch_idx, matrix, sim_fn):\n",
    "    ''' Ranks the similarity of all of the words to the target word.\n",
    "  # NOTE: THIS DOCSTRING WAS UPDATED ON JAN 24, 12:51 PM.\n",
    "  Inputs:\n",
    "    target_word_index: The index of the word we want to compare all others against.\n",
    "    matrix: Numpy matrix where the ith row represents a vector embedding of the ith word.\n",
    "    similarity_fn: Function that should be used to compared vectors for two word\n",
    "      ebeddings. Either compute_dice_similarity, compute_jaccard_similarity, or\n",
    "      compute_cosine_similarity.\n",
    "\n",
    "  Returns:\n",
    "    A length-n list of integer word indices, ordered by decreasing similarity to the \n",
    "    target word indexed by word_index\n",
    "  '''\n",
    "    n_chs = matrix.shape[1]\n",
    "    v1 = matrix[:,target_ch_idx]   \n",
    "    SimLst1 = [sim_fn(v1,matrix[:,i]) for i in range(target_ch_idx)]\n",
    "    SimLst2 = [sim_fn(v1,matrix[:,i]) for i in range((target_ch_idx+1),n_chs)]\n",
    "#     #--------\n",
    "#     # parallel\n",
    "#     num_cores = multiprocessing.cpu_count()\n",
    "#     pool = multiprocessing.Pool(processes=num_cores)\n",
    "#     SimLst1 = pool.map(process_impv_rk_chs, [(sim_fn,v1,matrix[:,i]) for i in range(target_ch_idx)])    \n",
    "#     SimLst2 = pool.map(process_impv_rk_chs, [(sim_fn,v1,matrix[:,i]) for i in range((target_ch_idx+1),n_chs)])\n",
    "#     # parallel\n",
    "#     #--------\n",
    "    SimLst = SimLst1 +[0] + SimLst2\n",
    "    retMaxIdx = np.argmax(SimLst); retMax = SimLst[retMaxIdx]\n",
    "    SimLst = SimLst1 +[retMax] + SimLst2\n",
    "    retMinIdx = np.argmin(SimLst); retMin = SimLst[retMinIdx]\n",
    "    ret = [retMaxIdx, retMax, retMinIdx, retMin]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples, document_names, vocab = read_in_shakespeare()\n",
    "N= len(vocab)\n",
    "vocab_to_id = dict(zip(vocab, range(0, len(vocab))))\n",
    "def read_in_shakespeare_character_sentence():\n",
    "    character_word={}\n",
    "    ch_lst = []\n",
    "    with open('will_play_text.csv') as f:\n",
    "        csv_reader = csv.reader(f, delimiter=';')\n",
    "        for row in csv_reader:    \n",
    "            character = row[4]\n",
    "            ch_lst.append(character)\n",
    "            line = row[5]\n",
    "            line_tokens = re.sub(r'[^a-zA-Z0-9\\s]', ' ', line).split()\n",
    "            line_tokens = [token.lower() for token in line_tokens]\n",
    "            if(not  character in character_word):\n",
    "                character_word[character]=np.zeros((N, 1), dtype = np.int32)\n",
    "            for token in line_tokens: character_word[character][  vocab_to_id[token]  ]+=1\n",
    "    return character_word,ch_lst\n",
    "\n",
    "def compute_similarity(character_word, sim_fn):\n",
    "    character = list(character_word.keys()) # this is a dictionary\n",
    "    num_character=len(character_word)\n",
    "    similarity = {}\n",
    "    for i in range(num_character):\n",
    "        #print(i) \n",
    "        for j in range(i+1, num_character): \n",
    "            similarity[(character[i], character[j])]=sim_fn(  character_word[character[i]], character_word[character[j]]   )\n",
    "    return similarity\n",
    "    \n",
    "\n",
    "character_word,ch_lst=read_in_shakespeare_character_sentence()\n",
    "similarity_fns = [compute_cosine_similarity, compute_jaccard_similarity, compute_dice_similarity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HW3 report: Mingyang Liu, Yezheng Li 2018-01-30 22:56:00.766972\n",
      "------------------------------------PART I--------------------------------------\n",
      "------------------------------------PART II-------------------------------------\n",
      "\u001b[1;31;10m----------------------------------------\n",
      "The fourth column of will_play_text.csv contains the name of the character who spokeeach line. Using the methods described above, which characters are most similar? Least similar?\n",
      "----------------------------------------\u001b[0m\n",
      "\n",
      "The most/ least similar pair using compute_cosine_similarity are:\n",
      "most similar pair ('Second Pirate', 'Outlaws'), least similar pair ('Outlaws', 'Mariner')\n",
      "The most/ least similar pair using compute_jaccard_similarity are:\n",
      "most similar pair ('Second Pirate', 'Outlaws'), least similar pair ('Outlaws', 'Mariner')\n",
      "The most/ least similar pair using compute_dice_similarity are:\n",
      "most similar pair ('Second Pirate', 'Outlaws'), least similar pair ('Outlaws', 'Mariner')\n",
      "\u001b[1;31;10m----------------------------------------\n",
      "Shakespeare’s plays are traditionally classified into comedies, histories, and tragedies. Can you use these vector representations to cluster the plays?\n",
      "----------------------------------------\u001b[0m\n",
      "----------------------------------------\n",
      "There are 16 Comedies 10 Histories 12 Tragedies according to https://en.wikipedia.org/wiki/Shakespeare%27s_plays:\n",
      "\n",
      "labels_pred [0, 2, 2, 2, 0, 0, 0, 1, 2, 2, 1, 1, 1, 1, 0, 1, 0, 2, 1, 1, 0, 2, 0, 1, 1, 2, 0, 0, 2, 2, 0, 0, 0, 0, 1, 1]\n",
      "\t0\t1\t2\n",
      "Comedies  6.667% \u001b[1;31;10m66.67%\u001b[0m \u001b[1;31;10m58.33%\u001b[0m\n",
      "Histories 33.33% 33.33% 33.33%\n",
      "Tragedies \u001b[1;31;10m60.00%\u001b[0m 0.000% 8.333%\n",
      "\u001b[1;31;10m----------------------------------------\n",
      "Do the vector representations of female characters differ distinguishably from male ones?\n",
      "----------------------------------------\u001b[0m\n",
      "According to http://www.namenerds.com/uucn/shakes.html, we automatically identify  318 males and 76 females (but actually with some manual work, we can identify much more.)\n",
      "Amongst the identified ones, we have  254 males and  71 females shown in will_play_text.csv\n",
      "\tcosine\tjaccard\tdice\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "slice indices must be integers or None or have an __index__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4b0ba373ea57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;31m# print(\"mat_ch_word\",mat_ch_word)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\tcosine\\tjaccard\\tdice'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMales\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMales\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrank_ch_return_max_min_maxIdx_minIdx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mch_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mterm_ch_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim_fn\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msim_fn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msimilarity_fns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;31m#     print(\"temp\",temp)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: slice indices must be integers or None or have an __index__ method"
     ]
    }
   ],
   "source": [
    "import time,datetime\n",
    "#-------------------------\n",
    "T0 = time.time()\n",
    "print(\"HW3 report: Mingyang Liu, Yezheng Li\",datetime.datetime.now())\n",
    "print(\"------------------------------------PART I--------------------------------------\")\n",
    "print(\"------------------------------------PART II-------------------------------------\")\n",
    "#---------------------------\n",
    "# from skeleton_hw3.py\n",
    "tuples, document_names, vocab = read_in_shakespeare()\n",
    "# print('Computing term document matrix...')\n",
    "td_matrix = create_term_document_matrix(tuples, document_names, vocab)\n",
    "# td_matrix_just_sentence_len = create_term_document_matrix_just_sentence_len(tuples, document_names, vocab)\n",
    "print('''\\033[1;31;10m----------------------------------------\n",
    "The fourth column of will_play_text.csv contains the name of the character who spokeeach line. Using the methods described above, which characters are most similar? Least similar?\n",
    "----------------------------------------\\033[0m\n",
    "''')\n",
    "tuples, ch_names = read_character_in_shakspeare() #, vocab \n",
    "n_chs = len(ch_names)\n",
    "# print('Computing term document matrix... (character)')\n",
    "term_ch_matrix = create_term_document_matrix(tuples, ch_names, vocab)\n",
    "T1 = time.time()\n",
    "# print(\"Time elapsed:\",T1  - T0,\"(\",T1-T0,\")\")\n",
    "similarity_fns = [compute_cosine_similarity, compute_jaccard_similarity, compute_dice_similarity]\n",
    "# Dice's distance violates triangular inequality while first two obey. The frist two can find max pair by three (possibly only two) steps.\n",
    "# print('''Notice there are \n",
    "# -> six lines with empty character '   '  in will_play_text.csv,\n",
    "# -> not all characters are gender-identifiable, for example, ''\n",
    "# we discuss four cases (including/ excluding empty character, with all data, focus only on gender-identifiable characters:''')\n",
    "# print(\"\\033[1;32;10mThe most/least similar pair (including '  ' character)\\033[0m\")\n",
    "\n",
    "\n",
    "for sim_fn in similarity_fns:\n",
    "    print('The most/ least similar pair using %s are:' %  sim_fn.__qualname__)\n",
    "    start_time = time.time()\n",
    "    similarity_pair = compute_similarity(character_word, sim_fn)  \n",
    "    elapsed_time = time.time() - start_time\n",
    "    rank = sorted(similarity_pair, key=similarity_pair.get, reverse=True) \n",
    "#     print(elapsed_time) \n",
    "    print('most similar pair %s, least similar pair %s' % (rank[0], rank[-1]))\n",
    "\n",
    "# print(\"\\033[1;32;10mThe most/least similar pair (excluding '  ' character)\\033[0m\")\n",
    "# term_ch_matrix2 = term_ch_matrix[1:,1:]\n",
    "\n",
    "\n",
    "T2 = time.time()\n",
    "# print(\"Time elapsed:\", T2  - T0,\"(\",T2-T1,\")\")\n",
    "#------------------------------------------------------------------------------------\n",
    "print('''\\033[1;31;10m----------------------------------------\n",
    "Shakespeare’s plays are traditionally classified into comedies, histories, and tragedies. Can you use these vector representations to cluster the plays?\n",
    "----------------------------------------\\033[0m''')\n",
    "# https://en.wikipedia.org/wiki/Shakespeare%27s_plays\n",
    "Comedies = ['The Tempest','Two Gentlemen of Verona','Merry Wives of Windsor','Measure for measure',       \\\n",
    "'A Comedy of Errors', 'Much Ado about nothing', \"Loves Labours Lost\", \"A Midsummer nights dream\", \\\n",
    "            \"Merchant of Venice\", \"As you like it\", \"Taming of the Shrew\", \"Alls well that ends well\",      \\\n",
    "            \"Twelfth Night\", \"A Winters Tale\", \"Pericles\", \"The Two Noble Kinsmen\" ]\n",
    "Histories = [\"King John\", \"Henry IV\", \"Henry V\", \"Henry VI Part 1\", \"Henry VI Part 2\",      \\\n",
    "        \"Henry VI Part 3\",\"Richard II\", \"Richard III\", \"Henry VIII\", \"Edward III\"]\n",
    "Tragedies = [\"Troilus and Cressida\", \"Coriolanus\", \"Titus Andronicus\", \"Romeo and Juliet\", \"Timon of Athens\",     \\\n",
    "             \"Julius Caesar\", \"macbeth\", \"Hamlet\", \"King Lear\", \"Othello\", \"Antony and Cleopatra\", \"Cymbeline\"]\n",
    "print(\"----------------------------------------\")\n",
    "print(\"There are\", len(Comedies),\"Comedies\", len(Histories), \"Histories\", len(Tragedies), \"Tragedies according to https://en.wikipedia.org/wiki/Shakespeare%27s_plays:\")\n",
    "labels_true = [(0*(doc in Comedies) + 1*(doc in Histories) + 2*(doc in Tragedies) ) for doc in document_names]\n",
    "from sklearn.cluster import KMeans, SpectralClustering \n",
    "# ------\n",
    "# KMeans has randomness -- unstable?\n",
    "kmeans_model = KMeans(n_clusters=3, random_state=1)\n",
    "kmeans_model.fit(td_matrix.transpose())\n",
    "labels_pred = list(kmeans_model.labels_)\n",
    "# print([document_names[i] for i in range(len(labels_true)) if 0 == labels_true[i]])\n",
    "print(\"\")\n",
    "# print('labels_true',labels_true)\n",
    "print('labels_pred',labels_pred)\n",
    "n_plays = len(labels_true)\n",
    "# print(\"\\tComedies\\tHistories\\tTragedies\")\n",
    "Percentage =np.zeros((3,3),dtype = np.float)\n",
    "\n",
    "for play_class in range(3):\n",
    "    for label in range(3): \n",
    "        Percentage[play_class,label] = sum([ play_class == labels_pred[i] for i in range(n_plays) if label == labels_true[i] ]) *100.0/ sum([ label == labels_true[i]  for i in range(n_plays)])\n",
    "# print(Percentage)\n",
    "print(\"\\t0\\t1\\t2\")\n",
    "print(\"Comedies  %.3f%% \\033[1;31;10m%.2f%%\\033[0m \\033[1;31;10m%.2f%%\\033[0m\"%(Percentage[0,0], Percentage[0,1], Percentage[0,2]))\n",
    "print(\"Histories %.2f%% %.2f%% %.2f%%\"%(Percentage[1,0], Percentage[1,1], Percentage[1,2]))\n",
    "print(\"Tragedies \\033[1;31;10m%.2f%%\\033[0m %.3f%% %.3f%%\"%(Percentage[2,0], Percentage[2,1], Percentage[2,2]))\n",
    "# ------\n",
    "# .fit(), .fit_predict()  -- not work, require square matrix as input? (strange)\n",
    "# Spec_model = SpectralClustering(n_clusters=3,affinity='precomputed')\n",
    "# labels_pred  = Spec_model.fit_predict(term_ch_matrix.transpose())\n",
    "# ------\n",
    "# GMM # too slow to run in Macbook(neither jupyter nor terminal python3 shell); process killed in biglab\n",
    "# from sklearn.mixture import GaussianMixture\n",
    "# estimator = GaussianMixture(n_components=3, max_iter=20, random_state=0)\n",
    "# estimator.fit(np.transpose(term_ch_matrix))\n",
    "# labels_pred = estimator.predict(np.transpose(term_ch_matrix.transpose))\n",
    "#------------------------------------------------------------------------------------\n",
    "print('''\\033[1;31;10m----------------------------------------\n",
    "Do the vector representations of female characters differ distinguishably from male ones?\n",
    "----------------------------------------\\033[0m''')\n",
    "# from sklearn.cluster import KMeans\n",
    "# kmeans_model = KMeans(n_clusters=2, random_state=1).fit(term_ch_matrix.transpose())\n",
    "# labels_pred = kmeans_model.labels_\n",
    "# print('labels_pred',labels_pred)\n",
    "with open('Male.txt') as f: \n",
    "    Males = [line.split('\\t')[0].strip().lower() for line in f.readlines()]\n",
    "    f.close()\n",
    "\n",
    "with open('Female.txt') as f: \n",
    "    Females = [line.split('\\t')[0].strip().lower() for line in f.readlines()]\n",
    "    f.close()\n",
    "print(\"According to http://www.namenerds.com/uucn/shakes.html, we automatically identify \", \\\n",
    "      len(Males), \"males and\", len(Females), \"females (but actually with some manual work, we can identify much more.)\")\n",
    "Males = [m for m in Males if m in ch_names]\n",
    "Females = [m for m in Females if m in ch_names]\n",
    "print(\"Amongst the identified ones, we have \",len(Males),\"males and \", len(Females), \"females shown in will_play_text.csv\")\n",
    "# mat_ch_word = np.array([character_word[ch] for ch in ch_lst])\n",
    "# print(\"mat_ch_word\",mat_ch_word)\n",
    "print('\\tcosine\\tjaccard\\tdice')\n",
    "for m in Males[::int(len(Males)/5)]:\n",
    "    temp = [rank_ch_return_max_min_maxIdx_minIdx(ch_names.index(m),term_ch_matrix, sim_fn ) for sim_fn in similarity_fns]\n",
    "#     print(\"temp\",temp)\n",
    "    temp = [ch_names[row[0]] for row in temp]\n",
    "    print('\\033[1;34;10m\\t %s\\033[0m\\t%s\\t%s\\t%s'%(m,temp[0],temp[1],temp[2]))\n",
    "print('------------------')\n",
    "for m in Females[::int(len(Females)/5)]:\n",
    "    temp = [rank_ch_return_max_min_maxIdx_minIdx(ch_names.index(m),term_ch_matrix, sim_fn ) for sim_fn in similarity_fns]\n",
    "#     print(\"temp\",temp)\n",
    "    temp = [ch_names[row[0]] for row in temp]\n",
    "    print('\\033[1;31;10m\\t %s\\033[0m\\t%s\\t%s\\t%s'%(m,temp[0],temp[1],temp[2]))\n",
    "# ch_names2 = [ch.lower() for ch in ch_names[1:]]\n",
    "# Not_identified = [ch for ch in ch_names2 if not ch in Males and not ch in Females]\n",
    "# print(len(Not_identified))\n",
    "# print(Not_identified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('will_play_text.csv') as f:\n",
    "        csv_reader = csv.reader(f, delimiter=';')\n",
    "        for row in csv_reader:\n",
    "            ch_name = row[4].lower()\n",
    "            if \"second pirate\"== ch_name: print(row)\n",
    "            line = row[5]\n",
    "            line_tokens = re.sub(r'[^a-zA-Z0-9\\s]', ' ', line).split()\n",
    "            line_tokens = [token.lower() for token in line_tokens]\n",
    "            tuples.append((ch_name, line_tokens))\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34;10m\t aaron\u001b[0m\tgloucester\tferdinand\tferdinand\n",
      "\u001b[1;34;10m\t caphis\u001b[0m\ttitus\ttitus\ttitus\n",
      "\u001b[1;34;10m\t ferdinand\u001b[0m\thamlet\tantonio\tantonio\n",
      "\u001b[1;34;10m\t marcellus\u001b[0m\thoratio\tfirst murderer\tfirst murderer\n",
      "\u001b[1;34;10m\t publius\u001b[0m\tbeatrice\tlord mayor\tlord mayor\n",
      "\u001b[1;34;10m\t vernon\u001b[0m\thotspur\tplantagenet\tplantagenet\n",
      "------------------\n",
      "\u001b[1;31;10m\t adriana\u001b[0m\tduke of york\tduke of york\tduke of york\n",
      "\u001b[1;31;10m\t cordelia\u001b[0m\thelena\tmiranda\tmiranda\n",
      "\u001b[1;31;10m\t hippolyta\u001b[0m\thotspur\tcromwell\tcromwell\n",
      "\u001b[1;31;10m\t margaret\u001b[0m\tbenedick\tjessica\tjessica\n",
      "\u001b[1;31;10m\t phrynia\u001b[0m\tghost of lady anne\tbeadle\tbeadle\n",
      "\u001b[1;31;10m\t volumnia\u001b[0m\tbrutus\tking\tking\n"
     ]
    }
   ],
   "source": [
    "for m in Males[::int(len(Males)/5)]:\n",
    "    temp = [rank_ch_return_max_min_maxIdx_minIdx(ch_names.index(m),term_ch_matrix, sim_fn ) for sim_fn in similarity_fns]\n",
    "#     print(\"temp\",temp)\n",
    "    temp = [ch_names[row[0]] for row in temp]\n",
    "    print('\\033[1;34;10m\\t %s\\033[0m\\t%s\\t%s\\t%s'%(m,temp[0],temp[1],temp[2]))\n",
    "print('------------------')\n",
    "for m in Females[::int(len(Females)/5)]:\n",
    "    temp = [rank_ch_return_max_min_maxIdx_minIdx(ch_names.index(m),term_ch_matrix, sim_fn ) for sim_fn in similarity_fns]\n",
    "#     print(\"temp\",temp)\n",
    "    temp = [ch_names[row[0]] for row in temp]\n",
    "    print('\\033[1;31;10m\\t %s\\033[0m\\t%s\\t%s\\t%s'%(m,temp[0],temp[1],temp[2]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Male)/7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
